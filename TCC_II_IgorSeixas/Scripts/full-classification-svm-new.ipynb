{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "import mahotas as mt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "\n",
    "from urllib.request import urlopen\n",
    "exec(urlopen(\"https://raw.githubusercontent.com/fhebert/CascadeSVC/main/CascadeSVC.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training dataset\n",
    "path = \"..\\Datasets\\Colombiam\\\\svm\\\\thyroid-crop-small-background-square-160\\\\\"\n",
    "path_names = os.listdir(path)\n",
    "\n",
    "# empty list to hold feature vectors and labels\n",
    "features_arr = []\n",
    "labels_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-2: Haralick Texture\n",
    "def fd_haralick(image):\n",
    "        # calculate haralick texture features for 4 types of adjacency\n",
    "        textures = mt.features.haralick(image)\n",
    "\n",
    "        # take the mean of it and return it\n",
    "        ht_mean = textures.mean(axis=0)\n",
    "\n",
    "        #for i in range(0,13):\n",
    "               #ht_mean[i] = -1* math.copysign(1.0, ht_mean[i]) *  math.log10(abs(ht_mean[i]))\n",
    "        return ht_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-1: Hu Moments\n",
    "def fd_hu_moments(image):\n",
    "    # Calculate Hu Moments.\n",
    "    feature = cv2.HuMoments(cv2.moments(image))\n",
    "    #for i in range(0,7):\n",
    "        #feature[i] = -1* math.copysign(1.0, feature[i]) *  math.log10(abs(feature[i]))\n",
    "    return feature.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Started extracting haralick textures and hu moments shape..\n",
      "[STATUS] processed folder: 1\n",
      "[STATUS] processed folder: 2\n",
      "[STATUS] processed folder: 3\n",
      "[STATUS] processed folder: 4-4a\n",
      "[STATUS] processed folder: 5-4b\n",
      "[STATUS] processed folder: 6-4c\n",
      "[STATUS] processed folder: 7-5\n"
     ]
    }
   ],
   "source": [
    "# loop over the training dataset\n",
    "print (\"[STATUS] Started extracting haralick textures and hu moments shape..\")\n",
    "for path_name in path_names:\n",
    "        cur_path = path + \"/\" + path_name\n",
    "        cur_label = path_name\n",
    "        i = 1\n",
    "        for file in glob.glob(cur_path + \"/*.jpg\"):\n",
    "                #print (\"Processing Image - {} in {}\".format(i, cur_label))\n",
    "                # read the training image\n",
    "                image = cv2.imread(file)\n",
    "\n",
    "                # convert the image to grayscale\n",
    "                #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                gray = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # extract features from image\n",
    "                fv_hu_moments = fd_hu_moments(gray)\n",
    "                fv_haralick   = fd_haralick(gray)\n",
    "\n",
    "                # concatened global features\n",
    "                #features = np.hstack([fv_haralick])\n",
    "                features = np.hstack(gray)\n",
    "\n",
    "                # append the feature vector and label\n",
    "                features_arr.append(features)\n",
    "                labels_arr.append(cur_label)\n",
    "\n",
    "                # show loop update\n",
    "                i += 1\n",
    "        print(\"[STATUS] processed folder: {}\".format(cur_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] labels encoded...\n",
      "[STATUS] feature vector normalized...\n",
      "[STATUS] target labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "[STATUS] target labels shape: (459,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.265041</td>\n",
       "      <td>0.680229</td>\n",
       "      <td>0.147665</td>\n",
       "      <td>0.178968</td>\n",
       "      <td>0.420804</td>\n",
       "      <td>0.143620</td>\n",
       "      <td>0.627777</td>\n",
       "      <td>0.676134</td>\n",
       "      <td>0.185943</td>\n",
       "      <td>0.518131</td>\n",
       "      <td>0.590165</td>\n",
       "      <td>0.761525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.378474</td>\n",
       "      <td>0.407834</td>\n",
       "      <td>0.091730</td>\n",
       "      <td>0.099778</td>\n",
       "      <td>0.524050</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.519818</td>\n",
       "      <td>0.683701</td>\n",
       "      <td>0.187433</td>\n",
       "      <td>0.635388</td>\n",
       "      <td>0.806729</td>\n",
       "      <td>0.467838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.619914</td>\n",
       "      <td>0.231794</td>\n",
       "      <td>0.126537</td>\n",
       "      <td>0.033474</td>\n",
       "      <td>0.860142</td>\n",
       "      <td>0.104730</td>\n",
       "      <td>0.586723</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>0.044169</td>\n",
       "      <td>0.828653</td>\n",
       "      <td>0.877482</td>\n",
       "      <td>0.386063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.558610</td>\n",
       "      <td>0.333435</td>\n",
       "      <td>0.135810</td>\n",
       "      <td>0.043171</td>\n",
       "      <td>0.710035</td>\n",
       "      <td>0.117208</td>\n",
       "      <td>0.612195</td>\n",
       "      <td>0.823778</td>\n",
       "      <td>0.066237</td>\n",
       "      <td>0.791825</td>\n",
       "      <td>0.834781</td>\n",
       "      <td>0.477711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.389983</td>\n",
       "      <td>0.575185</td>\n",
       "      <td>0.161108</td>\n",
       "      <td>0.119911</td>\n",
       "      <td>0.590239</td>\n",
       "      <td>0.151318</td>\n",
       "      <td>0.621828</td>\n",
       "      <td>0.735298</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>0.640629</td>\n",
       "      <td>0.681262</td>\n",
       "      <td>0.669299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.503214</td>\n",
       "      <td>0.717656</td>\n",
       "      <td>0.338695</td>\n",
       "      <td>0.120165</td>\n",
       "      <td>0.584086</td>\n",
       "      <td>0.327736</td>\n",
       "      <td>0.807701</td>\n",
       "      <td>0.862958</td>\n",
       "      <td>0.103850</td>\n",
       "      <td>0.726039</td>\n",
       "      <td>0.523632</td>\n",
       "      <td>0.846648</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.444760</td>\n",
       "      <td>0.637941</td>\n",
       "      <td>0.229218</td>\n",
       "      <td>0.129173</td>\n",
       "      <td>0.556929</td>\n",
       "      <td>0.218429</td>\n",
       "      <td>0.715555</td>\n",
       "      <td>0.809286</td>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.664959</td>\n",
       "      <td>0.606797</td>\n",
       "      <td>0.741703</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.475834</td>\n",
       "      <td>0.610967</td>\n",
       "      <td>0.228114</td>\n",
       "      <td>0.103216</td>\n",
       "      <td>0.514228</td>\n",
       "      <td>0.215787</td>\n",
       "      <td>0.711441</td>\n",
       "      <td>0.830039</td>\n",
       "      <td>0.117128</td>\n",
       "      <td>0.705506</td>\n",
       "      <td>0.648842</td>\n",
       "      <td>0.716991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.278408</td>\n",
       "      <td>0.324223</td>\n",
       "      <td>0.035212</td>\n",
       "      <td>0.147011</td>\n",
       "      <td>0.394345</td>\n",
       "      <td>0.027773</td>\n",
       "      <td>0.377811</td>\n",
       "      <td>0.535130</td>\n",
       "      <td>0.250924</td>\n",
       "      <td>0.528742</td>\n",
       "      <td>0.862563</td>\n",
       "      <td>0.300231</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.275507</td>\n",
       "      <td>0.604076</td>\n",
       "      <td>0.114314</td>\n",
       "      <td>0.170456</td>\n",
       "      <td>0.435012</td>\n",
       "      <td>0.108947</td>\n",
       "      <td>0.549043</td>\n",
       "      <td>0.627766</td>\n",
       "      <td>0.191019</td>\n",
       "      <td>0.518157</td>\n",
       "      <td>0.668451</td>\n",
       "      <td>0.651709</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.003246  0.265041  0.680229  0.147665  0.178968  0.420804  0.143620   \n",
       "1    0.003193  0.378474  0.407834  0.091730  0.099778  0.524050  0.080808   \n",
       "2    0.001432  0.619914  0.231794  0.126537  0.033474  0.860142  0.104730   \n",
       "3    0.001394  0.558610  0.333435  0.135810  0.043171  0.710035  0.117208   \n",
       "4    0.002771  0.389983  0.575185  0.161108  0.119911  0.590239  0.151318   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "454  0.001347  0.503214  0.717656  0.338695  0.120165  0.584086  0.327736   \n",
       "455  0.001630  0.444760  0.637941  0.229218  0.129173  0.556929  0.218429   \n",
       "456  0.001314  0.475834  0.610967  0.228114  0.103216  0.514228  0.215787   \n",
       "457  0.005560  0.278408  0.324223  0.035212  0.147011  0.394345  0.027773   \n",
       "458  0.004088  0.275507  0.604076  0.114314  0.170456  0.435012  0.108947   \n",
       "\n",
       "            7         8         9        10        11        12  Target  \n",
       "0    0.627777  0.676134  0.185943  0.518131  0.590165  0.761525       0  \n",
       "1    0.519818  0.683701  0.187433  0.635388  0.806729  0.467838       0  \n",
       "2    0.586723  0.823374  0.044169  0.828653  0.877482  0.386063       0  \n",
       "3    0.612195  0.823778  0.066237  0.791825  0.834781  0.477711       0  \n",
       "4    0.621828  0.735298  0.128186  0.640629  0.681262  0.669299       0  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "454  0.807701  0.862958  0.103850  0.726039  0.523632  0.846648       5  \n",
       "455  0.715555  0.809286  0.131799  0.664959  0.606797  0.741703       5  \n",
       "456  0.711441  0.830039  0.117128  0.705506  0.648842  0.716991       5  \n",
       "457  0.377811  0.535130  0.250924  0.528742  0.862563  0.300231       5  \n",
       "458  0.549043  0.627766  0.191019  0.518157  0.668451  0.651709       5  \n",
       "\n",
       "[459 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the target labels\n",
    "targetNames = np.unique(labels_arr)\n",
    "le          = LabelEncoder()\n",
    "labels      = le.fit_transform(labels_arr)\n",
    "print(\"[STATUS] labels encoded...\")\n",
    "\n",
    "# scale features in the range (0-1)\n",
    "scaler            = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaled_features = scaler.fit_transform(features_arr) #scaler.fit_transform(features_arr) #features_arr\n",
    "print(\"[STATUS] feature vector normalized...\")\n",
    "\n",
    "print(\"[STATUS] target labels: {}\".format(labels))\n",
    "print(\"[STATUS] target labels shape: {}\".format(labels.shape))\n",
    "\n",
    "data=np.array(rescaled_features)\n",
    "target=np.array(labels)\n",
    "df=pd.DataFrame(data)\n",
    "df['Target']=target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted Successfully\n",
      "Training features: (344, 13)\n",
      "Training labels: (344,)\n",
      "Test features: (115, 13)\n",
      "Test labels: (115,)\n"
     ]
    }
   ],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=77,stratify=y)\n",
    "print('Splitted Successfully')\n",
    "\n",
    "# have a look at the size of our feature vector and labels\n",
    "print (\"Training features: {}\".format(np.array(x_train).shape))\n",
    "print (\"Training labels: {}\".format(np.array(y_train).shape))\n",
    "print (\"Test features: {}\".format(np.array(x_test).shape))\n",
    "print (\"Test labels: {}\".format(np.array(y_test).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_loss_score = make_scorer(score_func=log_loss,greater_is_better=True,needs_proba=True)\n",
    "#\n",
    "#csvm = Pipeline([(\"scaler\",StandardScaler()),\n",
    "#                 (\"csvm\",CascadeSVC(fold_size=10000,verbose=False,\n",
    "#                                    kernel=\"rbf\",probability=True))])\n",
    "#\n",
    "## Variar o grid\n",
    "#model = GridSearchCV(estimator=csvm,\n",
    "#                          param_grid={\"csvm__C\" : [120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140], #10,100,1000,10000\n",
    "#                                      \"csvm__gamma\" : [0.0001,0.001,0.1,1]}, #0.0001,0.001,0.1,1\n",
    "#                          cv=5,n_jobs=5,verbose=10,scoring=log_loss_score,refit=True)\n",
    "#\n",
    "#model.fit(x_train, y_train)\n",
    "#\n",
    "#par1 = model.best_params_\n",
    "#res1 = pd.DataFrame({\n",
    "#    \"C\" : model.cv_results_[\"param_csvm__C\"],\n",
    "#    \"gamma\" : model.cv_results_[\"param_csvm__gamma\"],\n",
    "#    \"mean_test_score\" : model.cv_results_[\"mean_test_score\"],\n",
    "#    \"std_test_score\" : model.cv_results_[\"std_test_score\"]\n",
    "#})\n",
    "#print(par1)\n",
    "#print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] Creating the classifier..\n",
      "[STATUS] Fitting data/label to model..\n",
      "The Model is trained well with the given images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Parameters\n",
    "#param_grid={'C':[9900,9901,9902,9903,9904,9905,9906,9907,9908,9909,9910,9911,9912,9913,9914,9915,9916,9917,9918,9919,9920,9921,9922,9923,9924,9925,9926,9927,9928,9929,9930,9931,9932,9933,9934,9935,9936,9937,9938,9939,9940,9941,9942,9943,9944,9945,9946,9947,9948,9949,9950,9951,9952,9953,9954,9955,9956,9957,9958,9959,9960,9961,9962,9963,9964,9965,9966,9967,9968,9969,9970,9971,9972,9973,9974,9975,9976,9977,9978,9979,9980,9981,9982,9983,9984,9985,9986,9987,9988,9989,9990,9991,9992,9993,9994,9995,9996,9997,9998,9999,10000,10001,10002,10003,10004,10005,10006,10007,10008,10009,10010,10011,10012,10013,10014,10015,10016,10017,10018,10019,10020,10021,10022,10023,10024,10025,10026,10027,10028,10029,10030,10031,10032,10033,10034,10035,10036,10037,10038,10039,10040,10041,10042,10043,10044,10045,10046,10047,10048,10049,10050,10051,10052,10053,10054,10055,10056,10057,10058,10059,10060,10061,10062,10063,10064,10065,10066,10067,10068,10069,10070,10071,10072,10073,10074,10075,10076,10077,10078,10079,10080,10081,10082,10083,10084,10085,10086,10087,10088,10089,10090,10091,10092,10093,10094,10095,10096,10097,10098,10099,10100],'gamma':[0.1,],'kernel':['rbf']} #'kernel':['rbf','poly'] [0.0001,0.001,0.1,1] #0.1,1,10,100,1000,10000\n",
    "#param_grid={'C':[0.1,1,10,100,1000,10000]}\n",
    "param_grid={'C':[0.1,1,10,100,1000,10000],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf']} #'kernel':['rbf','poly'] [0.0001,0.001,0.1,1] #0.1,1,10,100,1000,10000\n",
    "\n",
    "# create the classifier\n",
    "print (\"[STATUS] Creating the classifier..\")\n",
    "#clf_svm = LinearSVC(dual=False, random_state=77)\n",
    "clf_svm = SVC(probability=True, cache_size=7000)\n",
    "model=GridSearchCV(clf_svm,param_grid)\n",
    "\n",
    "# fit the training data and labels\n",
    "print (\"[STATUS] Fitting data/label to model..\")\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Show the best model\n",
    "print('The Model is trained well with the given images')\n",
    "model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Data is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 2, 3, 2, 2, 3, 3, 4, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2,\n",
       "       4, 3, 3, 3, 4, 2, 2, 2, 2, 3, 2, 3, 2, 5, 3, 3, 5, 2, 2, 2, 3, 3,\n",
       "       2, 0, 2, 2, 2, 3, 3, 3, 2, 4, 3, 2, 3, 3, 3, 4, 2, 2, 3, 5, 2, 4,\n",
       "       3, 2, 4, 2, 2, 2, 3, 2, 3, 3, 0, 3, 3, 3, 3, 3, 4, 2, 2, 2, 3, 5,\n",
       "       3, 3, 2, 2, 2, 2, 3, 3, 3, 2, 5, 3, 2, 3, 2, 4, 2, 3, 2, 4, 3, 3,\n",
       "       3, 2, 2, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "print(\"The predicted Data is :\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual data is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 5, 0, 2, 4, 3, 2, 1, 2, 2, 0, 3, 3, 2, 2, 5, 3, 2, 2, 0, 3,\n",
       "       2, 2, 5, 2, 2, 3, 0, 2, 2, 4, 0, 3, 3, 3, 3, 4, 3, 5, 4, 3, 5, 3,\n",
       "       5, 0, 4, 2, 2, 4, 1, 3, 3, 3, 2, 4, 1, 5, 0, 4, 3, 3, 5, 2, 2, 5,\n",
       "       3, 2, 2, 3, 2, 4, 3, 3, 0, 4, 2, 2, 5, 4, 2, 4, 3, 5, 2, 2, 2, 2,\n",
       "       2, 4, 4, 3, 4, 4, 1, 5, 2, 1, 3, 5, 2, 4, 2, 0, 5, 0, 3, 0, 4, 4,\n",
       "       0, 4, 3, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The actual data is:\")\n",
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is 22.608695652173914% accurate\n",
      "[[ 1  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 3  1 16 15 10  5]\n",
      " [ 6  4 11  8 11  8]\n",
      " [ 2  0  4  2  1  1]\n",
      " [ 0  0  2  3  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.50      0.14         2\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.47      0.32      0.38        50\n",
      "           3       0.29      0.17      0.21        48\n",
      "           4       0.05      0.10      0.06        10\n",
      "           5       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.23       115\n",
      "   macro avg       0.15      0.18      0.13       115\n",
      "weighted avg       0.33      0.23      0.26       115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification_report(y_pred,y_test)\n",
    "print(f\"The model is {accuracy_score(y_pred,y_test)*100}% accurate\")\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the test images\n",
    "#test_path = \"..\\Datasets\\Colombiam\\\\svm\\\\thyroid-crop-small-background-square-160-tri\\\\6-4c\\\\\"\n",
    "#for file in glob.glob(test_path + \"/*.jpg\"):\n",
    "#        # read the input image\n",
    "#        image = cv2.imread(file)\n",
    "#\n",
    "#        # convert to grayscale\n",
    "#        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#\n",
    "#        # extract haralick texture from the image\n",
    "#        features = extract_features(gray)\n",
    "#\n",
    "#        # evaluate the model and predict label\n",
    "#        prediction = clf_svm.predict(features.reshape(1, -1))[0]\n",
    "#\n",
    "#        # show the label\n",
    "#        cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
    "#\n",
    "#        # display the output image\n",
    "#        cv2.imshow(\"Test_Image\", image)\n",
    "#        cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
