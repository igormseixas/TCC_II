{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/**\n",
    "* 2/2021\n",
    "* Pontifícia Universidade Católica de Minas Gerais\n",
    "* Advisor - Prof. Alexei Machado\n",
    "* Designed by:\n",
    "* @author Igor Machado Seixas - 561897\n",
    "* @version 0.10a\n",
    "*/\n",
    "'''\n",
    "\n",
    "'''\n",
    "/**\n",
    "* Libraries:\n",
    "* Numpy - PIL - sklearn - torch - sklearn\n",
    "*/\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation.\n",
    "transform_train = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.25,], std=[0.5,])])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.25,], std=[0.5,])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igormseixas\\TCC_II\\Datasets\\Colombiam\\thyroid-crop-small-background-360-train\n"
     ]
    }
   ],
   "source": [
    "# Configuration.\n",
    "#root_directory = f'..//Datasets//Colombiam//thyroid-cut'\n",
    "path = os.getcwd()\n",
    "root_directory = os.path.dirname(path)+'\\Datasets\\Colombiam\\\\thyroid-crop-small-background-360-train'\n",
    "test_root_directory = os.path.dirname(path)+'\\Datasets\\Colombiam\\\\thyroid-crop-small-background-360-test'\n",
    "print(root_directory)\n",
    "train_ratio = 1\n",
    "validation_ratio = .25\n",
    "rotation_angle = 90\n",
    "\n",
    "random_seed = 15\n",
    "torch.manual_seed(random_seed) # Preavesibility\n",
    "batch_size = 32\n",
    "pin_memory = True\n",
    "#num_workers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration.\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device('cuda')\n",
    "    print('Running on cuda')\n",
    "    # Distribute across \"2\" gpus\n",
    "    #model = nn.DataParallel(model)\n",
    "    #print('Running on multiple gpus')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Running on cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a dataset with a set of training and test set and a set of classes.\n",
    "# Param img_folder - contains the image folder path.\n",
    "# Param train_size - contains the size of the training set.\n",
    "# Param...\n",
    "def load_dataset(img_folder, test_folder, train_ratio, validation_ratio, transform_train, transform_test, rotation_angle=0, batch_size=64, data_augmentation=False):\n",
    "    image_data_train=[]\n",
    "    image_data_val=[]\n",
    "    image_data_test=[]\n",
    "    image_class=[]\n",
    "\n",
    "    file_name_memory = []\n",
    "    file_name_memory_train = []\n",
    "    file_name_memory_val = []\n",
    "\n",
    "    # Iteract in the files directory.\n",
    "    for dir in os.listdir(img_folder):\n",
    "        if dir.startswith('8'): continue\n",
    "        print(\"Train and Validation:\", dir)\n",
    "        file_name_memory = [s for s in os.listdir(os.path.join(img_folder, dir))] # Get all the names.\n",
    "        file_name_memory = list(zip(*(iter(file_name_memory),) * 1)) # Create group of 1 files.\n",
    "        # Randonize the names by group.\n",
    "        random.Random(random_seed).shuffle(file_name_memory)\n",
    "        # Get train_ratio to put into file_name_memory_train and file_name_memory_test.\n",
    "        file_name_memory_train = file_name_memory[:int(len(file_name_memory)*train_ratio)] # First n*train_ratio elements.\n",
    "        file_name_memory_val = file_name_memory_train[:int(len(file_name_memory_train)*validation_ratio)] # First n*validation_ratio elements.\n",
    "        \n",
    "        # Flat train list and validation.\n",
    "        file_name_memory_train = list(itertools.chain(*file_name_memory_train))\n",
    "        file_name_memory_val = list(itertools.chain(*file_name_memory_val))\n",
    "\n",
    "        for file in os.listdir(os.path.join(img_folder, dir)):\n",
    "            image_path = os.path.join(img_folder, dir,  file)\n",
    "\n",
    "            # The first train_ratio times append to the image_data_train.\n",
    "            if file in file_name_memory_train:\n",
    "                image = transform_train(Image.open(image_path)) # Train transformation for train and val.\n",
    "                image = np.array(image)\n",
    "                if file in file_name_memory_val:\n",
    "                    # Append de image data to the validation set.\n",
    "                    image_data_val.append([image,int(dir[0])]) \n",
    "                else:\n",
    "                    # Append de image data to the training set.\n",
    "                    image_data_train.append([image,int(dir[0])])\n",
    "\n",
    "            #else:\n",
    "            #    image = transform_test(Image.open(image_path)) # Test transformation for train and val.\n",
    "            #    image = np.array(image)\n",
    "            #    # Append de image data to an image_data_x array and a image_data_y with the classifiers.\n",
    "            #    image_data_test.append([image,int(dir[0])])\n",
    "\n",
    "        image_class.append(dir)\n",
    "\n",
    "    # Iteract in the files directory.\n",
    "    for dir in os.listdir(test_folder):\n",
    "        if dir.startswith('8'): continue\n",
    "        print(\"Test:\", dir)\n",
    "        for file in os.listdir(os.path.join(test_folder, dir)):\n",
    "            test_path = os.path.join(test_folder, dir,  file)\n",
    "            \n",
    "            image = transform_test(Image.open(test_path)) # Test transformation for train and val.\n",
    "            image = np.array(image)\n",
    "            # Append de image data to an image_data_x array and a image_data_y with the classifiers.\n",
    "            image_data_test.append([image,int(dir[0])])\n",
    "\n",
    "\n",
    "    # Defining data training, validation and test sizes.\n",
    "    train_size = int(train_ratio * len(image_data_train))\n",
    "    val_size = len(image_data_train) - train_size\n",
    "\n",
    "    # Transform into DataLoader \n",
    "    train_dl = DataLoader(image_data_train, batch_size=batch_size, shuffle=True, pin_memory=pin_memory)\n",
    "    val_dl = DataLoader(image_data_val, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
    "    test_dl = DataLoader(image_data_test, batch_size=batch_size, shuffle=False, pin_memory=pin_memory)\n",
    "    classes = np.array(image_class)\n",
    "    #print('Train Mean and STD:', get_mean_and_std(train_dl))\n",
    "    #print('Validation Mean and STD:', get_mean_and_std(val_dl))\n",
    "    #print('Test Mean and STD:', get_mean_and_std(test_dl))\n",
    "\n",
    "    return train_dl, val_dl, test_dl, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to be loaded.\n",
    "model = models.mobilenet_v3_large(pretrained=True)\n",
    "model = model.to(device=device)\n",
    "\n",
    "# Loss and optimizer.\n",
    "learning_rate = 1e-3 #It was 0.07\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr= learning_rate) # Adam\n",
    "checkpoint = torch.load('./my_model/my_model_5_classification/my_model_98_MobileNet_pre_large.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "0.3034930234944335\n"
     ]
    }
   ],
   "source": [
    "# Check epoch and loss.\n",
    "print (checkpoint['epoch'])\n",
    "print (checkpoint['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuraccy of the training set.\n",
    "# Function to give accuracy of a given data set. It will returns the predict and output to\n",
    "# check using other metrics.\n",
    "def check_acc(dataloader, model, device):\n",
    "    # Get the data.\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    predict = []\n",
    "    target = []\n",
    "\n",
    "    # Set model to eval\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data,targets) in enumerate(dataloader):\n",
    "            #print('Batch:', batch_idx)\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            ## Forward Pass\n",
    "            scores = model(data)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == targets).sum()\n",
    "            num_samples += predictions.size(0)    \n",
    "\n",
    "            predict = predict + predictions.to(device=\"cpu\").numpy().tolist()\n",
    "            target = target + targets.to(device=\"cpu\").numpy().tolist()\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    "        )\n",
    "\n",
    "    result = float(num_correct) / float(num_samples) * 100\n",
    "    #model.train()\n",
    "    return target, predict, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Validation: 1\n",
      "Train and Validation: 2\n",
      "Train and Validation: 3\n",
      "Train and Validation: 4-4a\n",
      "Train and Validation: 5-4b\n",
      "Train and Validation: 6-4c\n",
      "Train and Validation: 7-5\n",
      "Test: 1\n",
      "Test: 2\n",
      "Test: 3\n",
      "Test: 4-4a\n",
      "Test: 5-4b\n",
      "Test: 6-4c\n",
      "Test: 7-5\n",
      "Training size:  3912\n",
      "Validation size:  1304\n",
      "Test size:  134\n",
      "Total size:  5350\n"
     ]
    }
   ],
   "source": [
    "# Get train and test data.\n",
    "train_dl, val_dl, test_dl, classes = load_dataset(root_directory, test_root_directory, train_ratio, validation_ratio, transform_train, transform_test, batch_size=batch_size)\n",
    "# Print size of training, validation and test sets.\n",
    "print(\"Training size: \", len(train_dl.dataset))\n",
    "print(\"Validation size: \", len(val_dl.dataset))\n",
    "print(\"Test size: \", len(test_dl.dataset))\n",
    "print(\"Total size: \", len(train_dl.dataset)+len(val_dl.dataset)+len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 420 / 3912 with accuracy 10.74\n",
      "\n",
      "Results on the training set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.11      0.97      0.19       432\n",
      "           3       0.00      0.00      0.00       180\n",
      "           4       0.00      0.00      0.00      1176\n",
      "           5       0.00      0.00      0.00       936\n",
      "           6       0.00      0.00      0.00       732\n",
      "           7       0.00      0.00      0.00       456\n",
      "\n",
      "    accuracy                           0.11      3912\n",
      "   macro avg       0.02      0.14      0.03      3912\n",
      "weighted avg       0.01      0.11      0.02      3912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_output, train_predict, _ = check_acc(train_dl, model, device)\n",
    "print('\\nResults on the training set:')\n",
    "print(classification_report(train_output, train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 142 / 1304 with accuracy 10.89\n",
      "\n",
      "Results on the validating set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.11      0.99      0.20       144\n",
      "           3       0.00      0.00      0.00        60\n",
      "           4       0.00      0.00      0.00       392\n",
      "           5       0.00      0.00      0.00       312\n",
      "           6       0.00      0.00      0.00       244\n",
      "           7       0.00      0.00      0.00       152\n",
      "\n",
      "    accuracy                           0.11      1304\n",
      "   macro avg       0.02      0.14      0.03      1304\n",
      "weighted avg       0.01      0.11      0.02      1304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "val_output, val_predict, _ = check_acc(val_dl, model, device)\n",
    "print('\\nResults on the validating set:')\n",
    "print(classification_report(val_output, val_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 15 / 134 with accuracy 11.19\n",
      "\n",
      "Results on the validating set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.11      1.00      0.20        15\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00        38\n",
      "           5       0.00      0.00      0.00        32\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.11       134\n",
      "   macro avg       0.02      0.17      0.03       134\n",
      "weighted avg       0.01      0.11      0.02       134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#tp, fn, fp, tn = confusion_matrix(test_output, test_predict).ravel()\n",
    "test_output, test_predict, _ = check_acc(test_dl, model, device)\n",
    "print('\\nResults on the validating set:')\n",
    "print(classification_report(test_output, test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0  0  0  0]\n",
      " [ 5  0  0  0  0  0]\n",
      " [38  0  0  0  0  0]\n",
      " [32  0  0  0  0  0]\n",
      " [28  0  0  0  0  0]\n",
      " [16  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_output,test_predict))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
